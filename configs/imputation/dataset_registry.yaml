# Dataset Registry for Multi-Dataset RAG Imputation System
# This registry defines all available datasets for the imputation pipeline
# Each dataset can have both ChromaDB (vector) and TF-IDF (keyword) indices

datasets:
  # =============================================================================
  # ACTIVE DATASETS (indexed and ready for use)
  # =============================================================================

  # ============================================================
  # TOXIGEN DATASETS - Explicit Hate Speech by Demographic Group
  # ============================================================
  toxigen_annotated:
    name: "ToxiGen Annotated Dataset"
    description: "Human-annotated toxic and neutral content with toxicity scores"

    source:
      path: "data/toxigen_datasets/annotated/train.csv"
      format: "csv"
      text_column: "text"
      label_columns: ["target_group", "toxicity_human", "toxicity_ai", "stereotyping", "intent"]

    label_mapping_file: "configs/imputation/mappings/toxigen_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/toxigen_annotated"
        collection_name: "toxigen_annotated"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/toxigen_annotated.pkl"
        max_features: 8000
        ngram_range: [1, 3]
        min_df: 2
        max_df: 0.9

    retrieval:
      top_k: 10
      min_similarity: 0.35
      enable_reranking: true

    post_processing:
      enable_obfuscation: true
      enable_label_injection: true

    metadata:
      total_samples: 8960
      demographics: 13
      has_human_annotations: true

  toxigen_hate_prompts:
    name: "ToxiGen Hate Prompts"
    description: "Machine-generated explicit hate speech prompts targeting 16 demographic groups"

    source:
      path: "data/toxigen_datasets/prompts/hate"
      format: "csv_directory"  # Multiple CSV files in directory
      text_column: "text"
      # Label is inferred from filename (e.g., hate_asian_1k.csv -> demographic: asian)
      label_from_filename: true
      filename_pattern: "hate_{demographic}_1k.csv"

    label_mapping_file: "configs/imputation/mappings/toxigen_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/toxigen_hate"
        collection_name: "toxigen_hate_prompts"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/toxigen_hate.pkl"
        max_features: 15000
        ngram_range: [1, 4]
        min_df: 1
        max_df: 0.85

    retrieval:
      top_k: 15
      min_similarity: 0.3
      enable_reranking: true

    post_processing:
      enable_obfuscation: true
      enable_label_injection: true

    metadata:
      total_samples: 16000
      demographics: 16
      prompt_type: "hate"
      samples_per_demographic: 1000

  # DISABLED: toxigen_neutral_prompts - Not useful for RAG (we want harmful content examples)
  # toxigen_neutral_prompts:
  #   name: "ToxiGen Neutral Prompts"
  #   description: "Machine-generated neutral content about 16 demographic groups"
  #   ...intentionally not indexed...

  # ============================================================
  # IMPLICITHATE DATASET - Subtle/Coded Hate Speech
  # ============================================================
  implicit_hate:
    name: "ImplicitHate (SALT-NLP)"
    description: "Subtle and implicit hate speech with 8 rhetorical strategies"

    source:
      path: "data/implicit_hate_datasets/raw/implicit_hate.csv"
      format: "csv"
      text_column: "post"
      label_columns: ["implicit_class", "extra_implicit_class"]

    label_mapping_file: "configs/imputation/mappings/implicit_hate_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/implicit_hate"
        collection_name: "implicit_hate"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/implicit_hate.pkl"
        max_features: 10000
        ngram_range: [1, 4]
        min_df: 2
        max_df: 0.9

    retrieval:
      top_k: 12
      min_similarity: 0.32
      enable_reranking: true

    post_processing:
      enable_obfuscation: true
      enable_label_injection: true

    metadata:
      total_samples: 6346
      implicit_classes: 8
      classes: ["white_grievance", "irony", "stereotypical", "threatening", "incitement", "inferiority", "dismissive", "dehumanization"]

  implicit_hate_train:
    name: "ImplicitHate Training Split"
    description: "Training split of ImplicitHate dataset (80%)"

    source:
      path: "data/implicit_hate_datasets/splits/train.csv"
      format: "csv"
      text_column: "post"
      label_columns: ["implicit_class"]

    label_mapping_file: "configs/imputation/mappings/implicit_hate_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/implicit_hate_train"
        collection_name: "implicit_hate_train"
        embedding_model: "all-MiniLM-L6-v2"

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/implicit_hate_train.pkl"

    retrieval:
      top_k: 10
      min_similarity: 0.35

    metadata:
      total_samples: 5076

  # ============================================================
  # DAVIDSON HATE SPEECH & OFFENSIVE LANGUAGE
  # ============================================================
  davidson:
    name: "Davidson Hate Speech & Offensive Language"
    description: "3-class dataset distinguishing hate speech from offensive language"

    source:
      path: "data/hate_speech_datasets/davidson/davidson_full.csv"
      format: "csv"
      text_column: "tweet"
      label_columns: ["class", "hate_speech", "offensive_language", "neither"]

    label_mapping_file: "configs/imputation/mappings/davidson_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/davidson"
        collection_name: "davidson_hate_speech"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/davidson.pkl"
        max_features: 10000
        ngram_range: [1, 3]
        min_df: 2
        max_df: 0.9

    retrieval:
      top_k: 10
      min_similarity: 0.35
      enable_reranking: true

    post_processing:
      enable_obfuscation: true
      enable_label_injection: true

    metadata:
      total_samples: 24783
      classes: 3
      class_names: ["hate_speech", "offensive_language", "neither"]
      distinguishes_hate_from_offensive: true

  # ============================================================
  # HATEXPLAIN - Explainable Hate Speech Detection
  # ============================================================
  hatexplain:
    name: "HateXplain"
    description: "Hate speech dataset with explainable rationales and target group annotations"

    source:
      path: "data/hate_speech_datasets/hatexplain/hatexplain_full.csv"
      format: "csv"
      text_column: "text"
      label_columns: ["label", "target_groups"]

    label_mapping_file: "configs/imputation/mappings/hatexplain_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/hatexplain"
        collection_name: "hatexplain"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/hatexplain.pkl"
        max_features: 10000
        ngram_range: [1, 3]
        min_df: 2
        max_df: 0.9

    retrieval:
      top_k: 10
      min_similarity: 0.35
      enable_reranking: true

    post_processing:
      enable_obfuscation: true
      enable_label_injection: true

    metadata:
      total_samples: 20148
      classes: 3
      class_names: ["hatespeech", "offensive", "normal"]
      target_groups: 10
      has_rationales: true

  # ============================================================
  # GAB HATE CORPUS - Hierarchical Hate Labels
  # ============================================================
  gab_hate_corpus:
    name: "Gab Hate Corpus"
    description: "Hierarchical hate labels (CV, HD, Hate) with target group annotations from Gab"

    source:
      path: "data/hate_speech_datasets/gab_hate_corpus/gab_hate_corpus.csv"
      format: "csv"
      text_column: "text"
      label_columns: ["cv", "hd", "hate"]

    label_mapping_file: "configs/imputation/mappings/gab_hate_corpus_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/gab_hate_corpus"
        collection_name: "gab_hate_corpus"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/gab_hate_corpus.pkl"
        max_features: 12000
        ngram_range: [1, 4]
        min_df: 2
        max_df: 0.85

    retrieval:
      top_k: 12
      min_similarity: 0.3
      enable_reranking: true

    post_processing:
      enable_obfuscation: true
      enable_label_injection: true

    metadata:
      total_samples: 27665
      hate_labels: ["CV", "HD", "Hate", "Not Hate"]
      target_groups: 10
      platform: "gab"

  # ============================================================
  # PHEME - Rumour Detection Dataset
  # ============================================================
  pheme:
    name: "PHEME Rumour Dataset"
    description: "Rumour/non-rumour tweets from 5 breaking news events"

    source:
      path: "data/hate_speech_datasets/pheme/pheme_full.csv"
      format: "csv"
      text_column: "text"
      label_columns: ["is_rumour", "event"]

    label_mapping_file: "configs/imputation/mappings/pheme_to_oasis.yaml"

    indices:
      chromadb:
        enabled: true
        path: "data/imputation/chromadb/pheme"
        collection_name: "pheme_rumours"
        embedding_model: "all-MiniLM-L6-v2"
        chunk_size: 256
        chunk_overlap: 25

      tfidf:
        enabled: true
        path: "data/imputation/tfidf/pheme.pkl"
        max_features: 8000
        ngram_range: [1, 3]
        min_df: 2
        max_df: 0.9

    retrieval:
      top_k: 10
      min_similarity: 0.35
      enable_reranking: false

    metadata:
      total_samples: 5802
      rumours: 1972
      non_rumours: 3830
      events: ["charliehebdo", "ferguson", "germanwings-crash", "ottawashooting", "sydneysiege"]

# Global settings for the imputation system
global_settings:
  # Default embedding model if not specified
  default_embedding_model: "all-MiniLM-L6-v2"

  # Cache settings
  cache:
    enabled: true
    ttl_seconds: 3600
    max_size_mb: 1024

  # Fallback chain configuration
  fallback_chain:
    - method: "chromadb"
      timeout_seconds: 5
    - method: "tfidf"
      timeout_seconds: 3
    - method: "llm_generation"
      timeout_seconds: 10
    - method: "static_bank"
      timeout_seconds: 1

  # Performance settings
  performance:
    batch_size: 32
    num_workers: 4
    use_gpu: false

  # Monitoring and logging
  monitoring:
    log_retrievals: true
    log_path: "logs/imputation/"
    metrics_enabled: true
    sample_rate: 0.1  # Sample 10% for quality metrics